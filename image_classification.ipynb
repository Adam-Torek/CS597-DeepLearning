{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4820ac8",
   "metadata": {},
   "source": [
    "## Assignment 3: Evaluation of Deep Learning Models on Image Classification\n",
    "\n",
    "### CS 597: Special Topics on Deep Learning\n",
    "\n",
    "### Adam Torek\n",
    "\n",
    "### Professor: Jun Zhuang\n",
    "\n",
    "### Spring 2025 Semester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c5830",
   "metadata": {},
   "source": [
    "### Library Imports/Setup\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "id": "291588f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:11:27.806190Z",
     "start_time": "2025-04-16T23:11:27.797214Z"
    }
   },
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50, swin_b, mobilenet_v3_small\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import RandomHorizontalFlip, Normalize, ToTensor, Compose, RandomRotation\n",
    "import tqdm"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "08162666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:11:40.159863Z",
     "start_time": "2025-04-16T23:11:40.075458Z"
    }
   },
   "source": [
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "8bedcd97",
   "metadata": {},
   "source": [
    "### Dataset Construction\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb756a48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:11:52.524078Z",
     "start_time": "2025-04-16T23:11:42.790117Z"
    }
   },
   "source": [
    "cifar_dataset = CIFAR10(download=True, root=\"data\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "44ae6eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:11:53.493207Z",
     "start_time": "2025-04-16T23:11:53.424878Z"
    }
   },
   "source": [
    "class CIFARSubsetDataSet(Dataset):\n",
    "    def __init__(self, dataset_tuples, transform=None):\n",
    "        self.dataset_tuples = dataset_tuples\n",
    "        self.transform = transform\n",
    "        self.dataset_len = len(dataset_tuples)\n",
    "        self.tensor_transform = ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dataset_item = self.dataset_tuples[idx]\n",
    "        image = self.tensor_transform(dataset_item[0])\n",
    "        \n",
    "        labels = [0,0]\n",
    "        labels[dataset_item[1]] = 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return {\"image\": image, \"label\": torch.tensor(labels, dtype=torch.float)}  "
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a3fbe98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:12:07.551976Z",
     "start_time": "2025-04-16T23:11:57.286377Z"
    }
   },
   "source": [
    "cifar_data_subset = []\n",
    "cifar_extraction_dataloader = iter(cifar_dataset)\n",
    "\n",
    "for image, label in cifar_extraction_dataloader:\n",
    "    if label == 0 or label == 1:\n",
    "        cifar_data_subset.append((image, label))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "0b262756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:12:07.762518Z",
     "start_time": "2025-04-16T23:12:07.757049Z"
    }
   },
   "source": [
    "augmentation_transforms = Compose([RandomHorizontalFlip(), RandomRotation(degrees=0.02)])\n",
    "\n",
    "cifar_binary_dataset = CIFARSubsetDataSet(dataset_tuples=cifar_data_subset, transform=augmentation_transforms)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ec040d94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:12:08.009650Z",
     "start_time": "2025-04-16T23:12:08.002044Z"
    }
   },
   "source": [
    "cifar_binary_dataloader = DataLoader(cifar_binary_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "faeeda4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:18:02.717855Z",
     "start_time": "2025-04-16T23:18:02.705367Z"
    }
   },
   "source": [
    "def train_model(model, num_epochs, learning_rate, dataloader, loss_func):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    training_loop = tqdm.tqdm(dataloader, leave=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_batch_steps = 0\n",
    "        total_batch_loss = 0\n",
    "        for batch in training_loop:\n",
    "            optimizer.zero_grad()\n",
    "            images = batch[\"image\"]\n",
    "            labels = batch[\"label\"]\n",
    "            outputs = model(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_batch_steps += len(images)\n",
    "            total_batch_loss += loss.item()\n",
    "\n",
    "            #training_loop.postfix(loss.item())\n",
    "\n",
    "        print(\"The average training loss after epoch {0} is {1}\".format(str(epoch), float(total_batch_loss/total_batch_steps)))\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "250e33a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T23:21:40.539290Z",
     "start_time": "2025-04-16T23:18:03.038556Z"
    }
   },
   "source": [
    "mobilenet_model = mobilenet_v3_small(weights=None)\n",
    "mobilenet_model.train()\n",
    "mobilenet_model.classifier[3] = torch.nn.Linear(in_features=mobilenet_model.classifier[3].in_features, out_features=2)\n",
    "train_model(mobilenet_model, num_epochs=num_epochs, learning_rate=learning_rate, dataloader=cifar_binary_dataloader, loss_func=torch.nn.BCEWithLogitsLoss())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [01:31<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average training loss after epoch 0 is 0.015999638637900354\n",
      "The average training loss after epoch 1 is 0.01265767001658678\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m mobilenet_model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m      3\u001B[0m mobilenet_model\u001B[38;5;241m.\u001B[39mclassifier[\u001B[38;5;241m3\u001B[39m] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mLinear(in_features\u001B[38;5;241m=\u001B[39mmobilenet_model\u001B[38;5;241m.\u001B[39mclassifier[\u001B[38;5;241m3\u001B[39m]\u001B[38;5;241m.\u001B[39min_features, out_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m train_model(mobilenet_model, num_epochs\u001B[38;5;241m=\u001B[39mnum_epochs, learning_rate\u001B[38;5;241m=\u001B[39mlearning_rate, dataloader\u001B[38;5;241m=\u001B[39mcifar_binary_dataloader, loss_func\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss())\n",
      "Cell \u001B[1;32mIn[14], line 13\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, num_epochs, learning_rate, dataloader, loss_func)\u001B[0m\n\u001B[0;32m     11\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(images)\n\u001B[0;32m     12\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_func(outputs, labels)\n\u001B[1;32m---> 13\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     15\u001B[0m total_batch_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(images)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ewactra_env\\Lib\\site-packages\\torch\\_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    524\u001B[0m     )\n\u001B[1;32m--> 525\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    527\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ewactra_env\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 267\u001B[0m _engine_run_backward(\n\u001B[0;32m    268\u001B[0m     tensors,\n\u001B[0;32m    269\u001B[0m     grad_tensors_,\n\u001B[0;32m    270\u001B[0m     retain_graph,\n\u001B[0;32m    271\u001B[0m     create_graph,\n\u001B[0;32m    272\u001B[0m     inputs,\n\u001B[0;32m    273\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    274\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    275\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ewactra_env\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    745\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    746\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5859bb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.Hardswish'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for classifier in mobilenet_model.classifier:\n",
    "    print(type(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5e972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ewactra_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
